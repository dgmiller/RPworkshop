# Linear Regression Example

### Objective

Learn how to develop your research using a reproducible workflow.

### To-Do

In this example, you will implement the following methods in `linear_regression.py` as well as tests for each method in `test_linear_regression.py`:

+ `simulate_data()`
+ `compare_models()`
+ `load_hospital_data()`
+ `prepare_data()`
+ `run_hospital_regression()`

**Let's Begin!**

Suppose you want to run a regression or a series of regressions on a dataset about hospital charge data found online at data.gov/health. There are a number of questions you might want to ask this dataset. For this example, suppose you are interested in whether the amount that a hospital bills Medicare has an effect on the amount actually paid out by Medicare.

*Simulating Data*

A really good practice is to create a simulated dataset of the kind of data you will be working with. This has a number of advantages. First, the simulation is completely distinct from the actual dataset and avoids concerns about private or proprietary data. Second, it helps you think critically about the how the data generating process (how the data came to be). This in turn helps you select an appropriate estimator because you know what the assumptions are about the data; you explicitly laid them out by simulating the dataset.

To begin, assume that the variable `x1` represents the average amount billed to Medicare. The name given for this variable in the hospital charges dataset is `average covered charges`. Suppose `x1` is exponentially distributed with rate parameter 9,000. You can change this at any time during the analysis to see what happens to the estimates if the distribution isn't quite what you expected. Now suppose there is another variable `x2` that you want to control for; it represents the number of hospital discharges associated with the given time period. Let it be poisson distributed with the rate parameter at 15. 

Next generate a vector of parameters `beta` that will represent the coefficients you want to estimate. In real world data sets, these parameters are never observed so it can be hard to know whether your method worked or not. While you can check all of your assumptions manually, it gives you more confidence if you can generate simulated data from a set of parameters and be able to check your parameter estimates against the simulated 'true' parameters.

Finally, the response variable `y` is generated by multiplying the matrix `X` (containing `x1` and `x2`) by the vector `beta` and adding a noise term `epsilon` which is always assumed to come from a zero-mean normal distribution.

*Testing Methods on Simulated Data*

Now that you can create simulated data, try writing a method to see if you can correctly estimate the true parameter values. Compare the implementations in two Python packages: `statsmodels` and `sklearn`. Both methods should produce identical estimates of the parameters. (Hint: this might make for a good unit test.)

One nice thing about statistical estimators is that they come with some guarantees, as long as all the assumptions are met sufficiently. This means that you can write tests to make sure that your estimator passes these guarantees. For example, you can check to see that the estimated parameters are within some tolerance of the true paramter values. So long as these tests pass, it indicates that the estimator is likely good.

*Preparing the Hospital Charges Dataset*

Now that you have validated your methods and know how to use each implementation in each package, you can start working with real data. The hospital charge data found at data.gov is not particularly large but it's not small either. It is not good practice to store large datasets on github. To get around this, it can sometimes be nice to sample observations from the large dataset and use that in continuing your analysis. A sample from the hospital charges dataset is found in the file `hospital_charge_sample.csv`. You will use this smaller file when writing methods to prepare the data for analysis.

Loading the data may seem straitforward, but when the data is raw it may need to go through some processing before it can be prepared for regression. One good practice is to keep the raw data and write functions that 'clean' the dataset. This may not be possible for all applications but it is good practice when it is possible and avoids many accidental errors. It also keeps a log (in code form) of how the data was changed so that you know what you're working with.

Once the data is cleaned, meaning it follows standard conventions of a dataset (e.g. Hadley Wickham's TIDY format) and can be easily loaded and worked with, then it is time to write a method that prepares the data for the linear regression model. This may involve log-transforming some variables or creating new variables from linear combinations of others. In this case, just like when you simulated data, you will use the variables `average covered charges` and `total discharges` from the dataset. You can decide how this data needs to enter the regression.

*Run the Regression*

Finally, it's time to write a method that runs the regression for you. This method should involve the methods that clean the data and prepare the data for the regression. In this case, the output should come from the `statsmodels` package and should return the output table in text form as shown below. As soon as everything works and all tests pass, you can have complete confidence that when you use the full dataset, everything will work as expected. Once you have the simple model working, you can begin to experiment or add complexity to the analysis.


```
                                 OLS Regression Results                                
=======================================================================================
Dep. Variable:                      y   R-squared (uncentered):                   1.000
Model:                            OLS   Adj. R-squared (uncentered):              1.000
Method:                 Least Squares   F-statistic:                          7.712e+04
Date:                Mon, 16 Sep 2019   Prob (F-statistic):                   2.20e-172
Time:                        07:49:31   Log-Likelihood:                         -128.37
No. Observations:                 100   AIC:                                      276.7
Df Residuals:                      90   BIC:                                      302.8
Df Model:                          10                                                  
Covariance Type:            nonrobust                                                  
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1            -1.1245      0.019    -60.643      0.000      -1.161      -1.088
x2             2.5044      0.020    123.914      0.000       2.464       2.545
x3             1.6085      0.017     96.915      0.000       1.576       1.642
x4             6.2893      0.018    342.086      0.000       6.253       6.326
x5            -1.5883      0.020    -80.022      0.000      -1.628      -1.549
x6            -5.1080      0.018   -282.434      0.000      -5.144      -5.072
x7             2.7557      0.018    149.065      0.000       2.719       2.792
x8            -3.6592      0.019   -193.913      0.000      -3.697      -3.622
x9             0.5256      0.018     28.674      0.000       0.489       0.562
x10            0.5650      0.017     33.328      0.000       0.531       0.599
==============================================================================
Omnibus:                        1.103   Durbin-Watson:                   2.281
Prob(Omnibus):                  0.576   Jarque-Bera (JB):                0.695
Skew:                          -0.184   Prob(JB):                        0.706
Kurtosis:                       3.179   Cond. No.                         19.0
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
```


Congratulations! You have completed this exercise using a fully reproducible workflow. As you continue to learn more, you will find other ways to continue making your research more reproducible. This helps collaborators and other colleagues understand your work and gives you more confidence that your work is correct and accurate.
